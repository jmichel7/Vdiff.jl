pine


  PINE 3.89   MAIN MENU                          Folder: (CLOSED)  0 Messages   

   ?     HELP               -  Get help using Pine

   C     COMPOSE MESSAGE    -  Compose and send a message

   I     FOLDER INDEX       -  View messages in current folder

   L     FOLDER LIST        -  Select a folder to view

   A     ADDRESS BOOK       -  Update address book

   S     SETUP              -  Configure or update Pine

   Q     QUIT               -  Exit the Pine program
Copyright 1989-1993.  PINE is a trademark of the University of Washington.
? Help                     P PrevCmd                  R RelNotes
O OTHER CMDS L [ListFldrs] N NextCmd                  K KBLock

[Opening "INBOX"...]
*

  PINE 3.89   MAIN MENU                            Folder: INBOX  78 Messages   

? Help                     P PrevCmd                  R RelNotes
O OTHER CMDS L [ListFldrs] N NextCmd                  K KBLock

[Folder "INBOX" opened with 78 messages]
  PINE 3.89   FOLDER INDEX                 Folder: INBOX  Message 45 of 78 NEW  

    39  Dec  8 Joel Runes          (1,241) Address to Ship Disk Drive for SFAAA 
+   40  Dec 12 Jean Michel        (99,613) Re: d2 feedback[D[D[D                
+   41  Dec 14 Jean Michel        (96,150) Re: d2 feedback                      
+   42  Dec 15 Jean Michel         (2,078) Re: d2 & software purchase           
+   43  Dec 15 Ekkehard Pofahl       (976) Berkeley Utilities                   
    44  Dec 15 Calypso             (1,652) Re: X command does not work on SAS/DO
  N 45  Dec 14 Kent A. Spencer     (1,551) Fwd: SAS POSITION OPENING            
  N 46  Dec 14 Kent A. Spencer     (2,739) Fwd: Re: POSITION WANTED: SAS PROGRAM
  N 47  Dec 15 CATLEY DENNIS B     (1,376) Re 'out of file handles creating WORK
  N 48  Dec 15 SIMME%PURCCVM.BITN  (1,299) sas under win32s...which version?    
  N 49  Dec 15 Paul Butler         (4,133) Re: FLAT File Merge                  
  N 50  Dec 15 whitloi1@WESTATPO.  (3,852) Re: What is the best way to merge/mat
  N 51  Dec 15 brentb@ORCA.FHCRC. (15,891) Re: Of Anecdotes, Antidotes, and Anti
  N 52  Dec 15 C Dhanwada            (988) Is there an FAQ?                     
  N 53  Dec 15 C Dhanwada          (1,380) Question on SAS graphics printing    
  N 54  Dec 15 Thomas M Skinner    (2,905) Re[2]: The Great Pentium Fire Drill  
  N 55  Dec 15 Thomas M Skinner    (3,885) Re[2]: The Great Pentium Fire Drill  
  N 56  Dec 15 Kenneth Chow        (1,149) proc build                           
  N 57  Dec 15 Thomas M Skinner    (4,006) Twas the Night before Star Trek...   

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V [ViewMsg]  N NextMsg   Spc NextPage    U Undelete    F Forward

44
   
  N 45  Dec 14 Kent A. Spencer     (1,551) Fwd: SAS POSITION OPENING            
    44  Dec 15 Calypso             (1,652) Re: X command does not work on SAS/DO


  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 44 of 78  70%      

Date: Thu, 15 Dec 1994 12:54:36 GMT
From: Calypso <calypso@CLARK.NET>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: X command does not work on SAS/DOS 6.04

Also be sure that command.com is somewhere in your path, for instance in
the autoexec.bat:

path=c:\;c:\dos;etc

Jasmine Pwu (d3803002@cc.ntu.edu.tw) wrote:
: : Richard Masse wrote:
: : >When I try to use the X command with SAS/DOS 6.04 for accessing the DOS
: : >prompt the system crash down and I need to reboot my computer.

: Please add the following line in your C:\CONFIG.SYS

:     DEVICE=C:\DOS\ANSI.SYS

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
:     DEVICE=C:\DOS\ANSI.SYS

: Remember to reboot your machine!  Good luck!


--
===============================================================
"If you think it's as good as Tolkien,             Calypso
 You need to read Tolkien again."             calypso@clark.net
===============================================================










DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 45 of 78  90%      

Date: Wed, 14 Dec 1994 19:51:00 EST
From: "Kent A. Spencer" <0005736508@MCIMAIL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Fwd: SAS POSITION OPENING

Metro Information Services has a need for  someone with 2+ years SAS
experience (HEAVY) who knows SAS Proc SQL.  Ideally, experience with SAS
Macro Processing is desired.   This is a position  in Richardson, Texas;
it's 6 to 9 months long for a large Manufacturer.

Metro would prefer to hire someone permanently but we're open to
Contractors.  The environment utilizes VAX/VMS and Oracle, so experience
with VAX or RDBMS is a plus. Periodic travel is required.  Salary range is
open!

Interested parties can contact Debbie Scales or Cyndi Piper at Metro
Information Services, 1/800-486-5287 or fax resume to 214/490-4681.  EMAIL
ADDRESS piperckp@connect.net or dscales@connect.net.

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
ADDRESS piperckp@connect.net or dscales@connect.net.

Debbie
dscales@connect.net
















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 46 of 78  35%      

Date: Wed, 14 Dec 1994 19:54:00 EST
From: "Kent A. Spencer" <0005736508@MCIMAIL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Fwd: Re: POSITION WANTED: SAS PROGRAMMER - RESEARCH AND STATISTICS

Let's not start this again.  Good luck John in your job hunting.
Drew
0005736508@MCIMail.Com

-----------------
Forwarded Message

Date:     Wed Dec 14, 1994  2:37 pm  EST
Source-Date: Wed, 14 Dec 1994 13:23:28 -0500
From:     Robert M. Hamer
          EMS: INTERNET / MCI ID: 376-5414
          MBX: hamer@gandalf.rutgers.edu

TO:     * Kent A. Spencer / MCI ID: 573-6508
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 66

TO:     * Kent A. Spencer / MCI ID: 573-6508
Subject:  Re: POSITION WANTED: SAS PROGRAMMER - RESEARCH AND STATISTICS
Message-Id: 44941214193744/0003765414DC2EM
Source-Msg-Id: <9412141941.AA12218@gatekeeper.mcimail.com>


johni21152@aol.com (JohnI21152) writes:

>POSITION WANTED:         SAS PROGRAMMER - RESEARCH AND STATISTICS

>I am a talented SAS programmer who has worked in a fast paced research
>firm
...bandwidth deleted...
>I am looking for another research position (in the Research Triangle Area)
>offering a variety of
...bandwidth deleted...
>John Iwaniszek, Raleigh, NC


 98
>John Iwaniszek, Raleigh, NC

I am so happy for you.  I can't tell you how much I, here in New Jersey,
as well as the tens of thousands of other SAS-L subscribers and
comp.soft-sys.sas readers around the USA and the world are to hear
that you are looking for a job in small triangular-shaped region in
North Carolina.  You've just sent this message world-wide, occupying
bandwidth on communications lines, and disk space on thousands if not
more computers, so that you can reach a few readers in your area.

This may not cost you money, but it costs _someone_ money.  And this
isn't personal; I am just of tired of seeing other advertisments, too.



--
--(Signature)      Robert M. Hamer hamer@gandalf.rutgers.edu 908 932 3145
--(1)  "Your" and "You're," or "Their" and "They're" are different words.
--(2)  In English, plurals are usually formed by adding "s," not "'s."

100
--(1)  "Your" and "You're," or "Their" and "They're" are different words.
--(2)  In English, plurals are usually formed by adding "s," not "'s."
--(3)  Subscribe and unsubscribe commands go to LISTSERV, not SAS-L.

















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 47 of 78  90%      

Date: Thu, 15 Dec 1994 12:53:13 +0000
From: CATLEY DENNIS B <CATLEY_DENNIS_B@LILLY.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re 'out of file handles creating WORK':

Re 'out of file handles creating WORK':

Thanks Ben, Melvin, and Alan King for the quick fix. For some strange
reason I made the error into a James Bond movie by reading more into
the WORK mention and seeing the APPENDAGE AUTO-LOAD FAILURE, he said
trying to masque his embarassment.

Long-live simple fixes!

nice to be back reading this list after two months of transitioning
to a new position. May everyone have a super holiday and get a new
pentium chip in their stocking!

--- Dennis
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100

--- Dennis
    Eli Lilly
    catley@lilly.com
















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 48 of 78 100%      

Date: Thu, 15 Dec 1994 10:01:40 EST
From: SIMME%PURCCVM.BITNET@uga.cc.uga.edu
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: sas under win32s...which version?

One of my net administrators is running win32s v1.1.88 on his network.
The spec sheets for SAS v6.10 specifies that v6.10 supports win32s v1.15.111.
Tech support in Cary further states than v1.15.111 is the *only* version of
win32s supported.

This net administrator says he will not upgrade win32s till next summer...
at which time he will upgrade to whatever the latest version is.

Does anyone know or have an idea of whether SAS v6.10 will run under
win32s v1.1.88?

Thanks in advance.

Ted Bandy, Purdue.
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 49 of 78  17%      

Date: Thu, 15 Dec 1994 11:03:57 EDT
From: Paul Butler <PAULB@UNX1.REALDEC.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: FLAT File Merge

                      Subject:                              Time:  10:59 AM
  OFFICE MEMO         RE: FLAT File Merge                   Date:  12/15/94
From: gautamg@escape.com (Gautam Guliani)

>On several occassions, I need to do the following:

>I have two flat files. One small one (200k records worst case) and a large
>one (35 million records worst case). I need to match the two datasets on
>a common variable. The large file has a large record size (3500 bytes)
>and I typically need only 200 bytes or so from it.

>In order to use the MERGE statement I have to read in the whole file as a
>SAS dataset. That is a problem(even if I read in only the 200 bytes). Is
>there a better way (ie efficient space usage is the primary criteria).
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 32
>SAS dataset. That is a problem(even if I read in only the 200 bytes). Is
>there a better way (ie efficient space usage is the primary criteria).

This quater's SAS Observations journal has an article concerning performance
evaluations of both traditional merges with the MERGE statement, SQL and
what
is known as Direct Access merges.  Good reading....

These flat files are sequential.  We cannot escape this.  Therefore one MUST
read in the contents of both files.

The big question here would be, Are the two FLAT files organized in sorted
order?  If they are, you can "merge" them together with one reading pass
of the big file, by using a variation of the classic interleaving algorithm:

Given Two TEXT Flat files:

Bigger file (text1.txt):
A fileone

 47
Bigger file (text1.txt):
A fileone
B fileone
C fileone
D fileone
E fileone
F fileone
G fileone
H fileone
I fileone

Smaller file (text2.txt):

B filetwo
E filetwo
H filetwo
X filetwo

Read in the big file and update it in place with key values from Text2.txt

 63

Read in the big file and update it in place with key values from Text2.txt
that match.  Use end= options to insure we don't read past end of file
when one file is smaller than the other.  End program when all of file
Text1.txt (the big file) is read and written out.  Add or update field
values from small file when there is a match.

data _null_;
length keyval keyval2 $ 1 rest rest2 $ 7;

 infile 'c:\temp\text1.txt' end=eof1;  /* Get record from Big file */
 input @1 keyval $ rest $;

if ^eof2 then do;
 infile 'c:\temp\text2.txt' end=eof2;  /* Get record from Small file */
 input @1 keyval2 $ rest2 $;
end;

do while((keyval < keyval2) & ^eof1); /* Read and output BIg file

 78

do while((keyval < keyval2) & ^eof1); /* Read and output BIg file
                                        Until you reach Keyval2 */
  file 'c:\temp\text1.txt';
  put @1 keyval $1. @3 rest $7.;
  infile 'c:\temp\text1.txt' end=eof1;
  input @1 keyval $ rest $;

end;

if keyval = keyval2 then rest = rest2; /* Check if BigKey = SmallKey */

if ^eof1 then do;  /* Update big file in place */
 file 'c:\temp\text1.txt';
 put  @1 keyval $1. @3 rest $7.;
end;

run;


 93
run;

Result:

A fileone
B filetwo
C fileone
D fileone
E filetwo
F fileone
G fileone
H filetwo
I fileone

This technique is much more efficient than a SQL merge, or than reading
in both files into SAS datasets, sorting and then writing results back
to a file.  The files, MUST be maintained in sorted order.  If they are
NOT sorted on the key value, then you cannot help but read them in to
SAS datasets, SORT and then MERGE. The Direct Access merge will help in

100
NOT sorted on the key value, then you cannot help but read them in to
SAS datasets, SORT and then MERGE. The Direct Access merge will help in
this case. See Observations for details.  The alternative is to maintain
the data with one of those TEXT based database products.


Paul Butler
Gartner Group
pbutler@rdc.gartner.com











DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 50 of 78  24%      

Date: Thu, 15 Dec 1994 11:33:01 EDT
From: whitloi1@WESTATPO.WESTAT.COM
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: What is the best way to merge/match?

    Subject: Re: What is the best way to merge/match?
    Summary: Flat merge is easy to code in SAS and more efficient than
             using DATA step views.
    Respondent: Ian Whitlock

    In answer to Gautam Guliani's <gautamg@ESCAPE.COM> question on how to
    merge flat files:

 GG>I have two flat files. One small one (200k records worst case) and a large
 GG>one (35 million records worst case). I need to match the two datasets on
 GG>a common variable. The large file has a large record size (3500 bytes)
 GG>and I typically need only 200 bytes or so from it.

    Tim Berryhill <TWB2@PGE.COM> suggests the use of DATA step views.  His
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 45

    Tim Berryhill <TWB2@PGE.COM> suggests the use of DATA step views.  His
    solution is neat and simple but I do not believe it is the best for the
    problem described. When dealing with the typical worst case Tim's final
    step

 TB>    DATA MATCH;
 TB>      MERGE BIG(IN=GOTIT)
 TB>            LITTLE(IN=WANTIT);
 TB>      BY ... ;
 TB>      IF WANTIT;
 TB>      IF NOT GOTIT THEN PUT 'Oops--missed' /* put keys here */ ;
 TB>    RUN;

    must still read 200 bytes of all 35 million records and move them into
    the program data vector before eliminating them.

    A flat merge is not hard to code in SAS and far more efficient since
    the minimum amount of information will be read from the big file.  I

 67
    A flat merge is not hard to code in SAS and far more efficient since
    the minimum amount of information will be read from the big file.  I
    illustrate with two files - LOOK has the variable LKEY and TARG has the
    variables TKEY and INFO where INFO stands for the information to be
    looked up, and LKEY and TKEY stand for the respective keys to the two
    files.

    The plan - for each loop of the DATA step - is

        1) Read LKEY from LOOK
        2) Read TKEYs from TARG while TKEY < LKEY
        3) If LKEY = TKEY then output to MATCH
           Otherwise output to NOMATCH

    Care is needed with the end-of-file of TARG when LKEY is beyond all
    TKEYs, the trailing @@ is needed to cover the case where a match
    immediately follows a non-match, and TKEY must be retained for the
    next loop of the DATA step.  Note that the loop stops when you run out
    of records in the little file.  Here is a model program.

 88
    next loop of the DATA step.  Note that the loop stops when you run out
    of records in the little file.  Here is a model program.

        filename look  'c:\sasl\out\junk1.dat' ;
        filename targ  'c:\sasl\out\junk2.dat' ;
        data match ( keep = lkey info rename = (lkey=key) )
             nomatch ( keep = lkey tkey ) ;
           retain tkey ;
           infile look ;
           input lkey ;
           infile targ end = eof ;
           do while ( tkey < lkey and not eof ) ;
              input tkey @@ ;
              if tkey < lkey then input ;
           end ;
           if lkey = tkey then
           do ;
              input @3 info $ /* @@ required when LOOK repeats keys */ ;
              output match ;

100
              input @3 info $ /* @@ required when LOOK repeats keys */ ;
              output match ;
           end ;
           else output nomatch ;
        run ;

    The case, where several variables make a key, is a little harder to
    code.  To simplify the code I would concatenate values to create a
    logical keys LKEY and TKEY.

 Ian Whitlock <whitloi1@westat.com>









DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 51 of 78   6%      

Date: Thu, 15 Dec 1994 15:02:04 GMT
From: brentb@ORCA.FHCRC.ORG
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: Of Anecdotes, Antidotes, and Antipodean Consumers

I have tried hard to fetch some content from this posting, and I simply cannot.
It very much seems to me that the issues are getting muddled.  In my opinion
there
are two issues and they are circular:

First issue: how does one who fears an effect from the FDIV problem get a
replacement.
In my opinion Intel blew this by setting up this "what apps are you using"
screening.
They should have said "we will replace the chip for anyone who wants a
replacement."
Just that simple. Intel's screening implies that you accept their
analysis of the impact of the problem, which brings us to the second issue.

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 11
analysis of the impact of the problem, which brings us to the second issue.

Second issue: what is the impact of the flaw.  Obviously this is a difficult
question.
>From the Intel, IBM, and other analyses we see many ways of looking at the
problem.
I suspect there will be additional analyses.  Now unfortunarely, the Intel
analysis
and the IBM analysis come from sources with vast economic interests.  These
analyses
should not automatically be rejected, but when studying them one needs to raise
the sensitivity setting on the BS detector.  Ulitimately, it is how one feels
about
the credibility of any analysis of potential impact of the flaw that leads back
to the
first issue.  After spending time assessing the problem and making a decision
the last
thing someone wants is to be questioned about it, especially when many of the
qualities

 17
thing someone wants is to be questioned about it, especially when many of the
qualities
of that decision are purely subjective ("how much risk am I willing to take"),
and the
source of the questions is Intel, which has vast economic interests, and
believes
their own self-serving analysis of the problem.

Therefore it is quite natural for some to simply say "Enough - just replace the
flawed
chips and quit wasting time on it" because of the complexity of making the
assessment.
Apparently that is close to what the FDA did, and giving IBM the benefit of
doubt, that
is what they did, and similarly HP, Dell, and probably many other I do not know
about.
The problem for Intel is that their approach to solving the problem makes those
taking this approach seem radical and hysteric.


 22
taking this approach seem radical and hysteric.

A minor comment:  After the crash of a particular type of aircraft I usually
feel
very comfortable flying that type of aircraft in future flights because I
assume that
there will be increased intensity in checking for the flaw that caused that
aircraft to fail.  Something similar applies here.  Those of us criticising
Intel
are not necessarily rejecting Intel.  I suspect the P6 (or whatever it is
called) will
have a lower chance of having floating point problems as a result of this
incident.

In <941213150209_2@ccm.hf.intel.com>, Thomas M Skinner
<Thomas_M_Skinner@CCM.FM.INTEL.COM> writes:
>Text item: Text_1
>
>Dear SAS-Lers,

 27
>
>Dear SAS-Lers,
>
>In the wake of the most recent WAVE (not OS/2) of stories about the
>Pentium, I thought I'd take the time to update the list on a few
>_relevant_ facts.
>
>Firstly I've heard directly from the Vice President of technology at
>SPSS who wrote:
>
>>This is Jon Peck at SPSS.  We have posted to the net our experience
>>comparing Pentium output with 486 output using SPSS for Windows and a
>>portion of our numerical testbed consisting of 746 different runs of
>>statistical procedures.  If you haven't seen the posting, we
>>encountered a few differences that were attributable to the Pentium,
>>although we cannot prove that they are the FDIV bug without excessive
>>analysis.  I would like to promise our users that we will rerun this
>>analysis with a fixed Pentium processor and post the results, but, of
>>course, we don't have one.

 33
>>analysis with a fixed Pentium processor and post the results, but, of
>>course, we don't have one.
>
>>Is there anything you can do to get us a fixed chip that we could use
>>to prove the source one way or the other?  If you can, I'll include
>>this in a posting to the net.
>
>>Jon K. Peck
>>Vice President for Technology
>>SPSS Inc
>
>To which I replied:
>
>     Jon,
>
>     I am forwarding this on to our tech support folks.  You should hear
>     something from them concerning a replacement. I am neither a tech
>     support person nor an official spokesperson, so I cannot do much
>     else for you.  As an application software product manager, I would

 38
>     support person nor an official spokesperson, so I cannot do much
>     else for you.  As an application software product manager, I would
>     be interested in your results however.
>
>     Tom Skinner
>
>To which he replied:
>
>>Thanks.  I talked to Richard Wirt yesterday, and I have already
>>received a new P90 to test.  We will be posting the results as soon as
>>we can install the new chip and rerun the jobs with differences.
>
>
>
>I also heard from William Gould, President of Stata Corp...
>
>>My name is William Gould and I am president of Stata Corporation, a
>>manufacturer of statistical software.
>

 44
>>manufacturer of statistical software.
>
>>A friend just passed along a posting from
>
>>    Newsgroup: comp.soft-sys.spss,
>>    Message-ID: <3c0m15$8a7@news.cloud9.net>,
>>    From: beveridg@cloud9.net (Andrew Beveridge)
>
>>in which he said
>
>>> But why is it that STATA and SPSS and SAS all indicate that there are
>>> problems using the Pentium, in the STATA case causing non-trivial
>>> errors with a significant probability.
>
>>This is not a fair representation of either my or StataCorp's position.
>>I have written a paper attempting to analyze the effect of the Pentium
>>problem on users of statistical software, a paper which started for
>>our internal use and has since made its way, with my permission, to the
>>Internet.  A copy is attached.

 49
>>our internal use and has since made its way, with my permission, to the
>>Internet.  A copy is attached.
>
>>My current feeling -- and what we are telling our users who call us on
>>the phones -- is that this bug is not a serious problem for users of
>>statistical software.  Nevertheless, we are now in the midst of
>>producing a Pentium-aware version of Stata.
>
>>Sincerely,
>
>>William Gould
>>wgould@stata.com
>
>>President, Stata Corporation
>>702 University Drive East
>>College Station, Texas 77480
>
>>800-782-8272   (1-800-STATAPC, USA)
>>800-248-8272   (Canada)

 55
>>800-782-8272   (1-800-STATAPC, USA)
>>800-248-8272   (Canada)
>>409-696-4600   (Worldwide)
>>409-696-4601   (Fax)
>
>I have not heard anything from SAS Institute directly.  Neither have I
>seen any of the new results from SPSS.  They are wise to compare apples
>to apples using a corrected Pentium instead of the i486 just as you too
>should if requested to verify your results.  As I have stated before,
>there are differences primarily in the transcendental functions that
>will make a 486 produce different results occasionally
>
>As far as the STATA fix goes, this fall into the category of Antidotes.
>Simply put, a workaround can be placed into application software that is
>affected by this flaw.  In fact, a recent news article states that Intel
>Corp. has pulled together a group to work on software that will detour
>around the flaw...  Intel scientist Richard Wirt announced the plan in a
>message to the internet (I'm trying to get a hold of this...)
>

 60
>message to the internet (I'm trying to get a hold of this...)
>
>The question arises, particularly after the post earlier today by a
>friend of a friend of a SI Deep Throat, concerning the optimization of
>R6.10 for i486 and Pentiums...  Why was a workaround not instituted in
>this release of the SAS Software.  The optimization was the result of an
>intensive program we have working with a variety of vendors, and do in
>fact have pretty much a full time engineer assigned to the Institute (we
>call these folks Strategic Software Technology Managers).
>
>To tell you the truth, I think he was as much surprised about the flaw
>as I was after the news was broke by Dr. Nicely.  My knowledge coming
>out of my own involvement in providing the Pentium compatibility labs
>with SAS routines last June was only to the extent that I knew they were
>looking at FPU's and the percentage of total instructions performed by
>the FPU.  I suspect they were looking for FPU intensive applications
>software for testing the potential frequency of the occurrence of an
>error, but it also possible that it hadn't even been discovered yet!  By
>the way, the applications I gave them were typical business apps

 66
>error, but it also possible that it hadn't even been discovered yet!  By
>the way, the applications I gave them were typical business apps
>designed to process millions of records, do a lot of I/O, Summaries and
>the like.  I also solicited the statisticians in the company to provide
>their apps.. such as QC, SAS/Graph, and  the like.
>
>I suppose it may have been possible to work with SI to incorporate a
>patch, however, I am not sure SI was even up to the task much less
>willing to delay shipment.  And I am not at all aware if our own folks
>had a handle on the full effect, which would be required to fix it.
>
>Many of you probably recall my persistent complaints about the delays in
>its release due to the MS WIN32S bug that forced all WIN32S apps to run
>on FPU equipped PC's.  I don't know how well SI is dealing with this,
>but it has the  subject of rumors lately here on the 'L.  So I certainly
>can't offer any insight into whether SI will do anything like what
>Strata is doing.  I do know that we are in the process of rotating our
>SSTM's so it may be a priority for the incoming person.
>

 71
>SSTM's so it may be a priority for the incoming person.
>
>A few other anecdotes:  I have heard from a few international SAS-Lers,
>and it seems that support is lacking, or at least slower in those
>countries... in particular Dr. Lazzarus (the Antipodean Consumer), down
>under for example, that must deal with the USA help folks.  I've got a
>list of international numbers.. but for the sake of the 'L, please
>contact me directly for these.
>
>Concerning the justification rule for getting a new chip:  I don't think
>you should look at it as jumping through a hoop... Folks, given that
>some 6 million or so chips have shipped, its going to take time to
>replace those used in applications that _really_ need it.  First of all
>chips don't grow on trees...it takes time to retool FABs...  Many intel
>folks are having their Holiday leave canceled as a result of all this.
>If you don't need it now ... wait awhile, for the sake of those who do.
>I think everybody understands that the _government_ can require it...we
>all recall the FDA's South American cyanide grape debacle... the point
>is that if they say so.. then you have to do what they say.  We gotta

 77
>all recall the FDA's South American cyanide grape debacle... the point
>is that if they say so.. then you have to do what they say.  We gotta
>help these folks right away.
>
>A volunteer on the help line (yes we are all pitching in regardless of
>background), related a call he got..  From the CIA.  When asked what
>applications they required that kind of precision for the person said
>"WE CAN'T TELL YOU!" ... oooookay.
>
>As far as those making assertions about what we have done with respect
>to all this..  I advised my SAS users in the FABS to check this out.  If
>they have a bad chip, use their best judgment to decide if they need a
>replacement.  I _DO_ know that we have not globally recalled these chips
>within the company.  If it makes anybody feel any better,
>
>I have been waiting _years_ for the internal purchase program to offer a
>PCI bus enables P90 machine for my home use.  We have such a Christmas
>special, and YES it does have a flawed chip.  I am pondering my
>decision... mainly looking at the applications I want to use it for (NOT

 82
>special, and YES it does have a flawed chip.  I am pondering my
>decision... mainly looking at the applications I want to use it for (NOT
>WORK RELATED...I GIVE ENOUGH OF MY TIME TO THIS COMPANY AS IS...) and it
>is mostly for net surfing via MOSAIC (I finally got to the WEB server at
>UGA that has the ATHENS FLAGPOLE newspaper..so I can keep track of my
>favorite town's activities.. BTW see y'all there this weekend.. and come
>to the Globe Friday evening if you're in town...) as well as multimedia,
>video editing and the like, not to mention games.   I have no fear
>whatsoever that this flaw would affect any of these. When I compare this
>deal to a PowerMAC similarly equipped for these activities...there's no
>comparison (I am still Positively Pentium preferenced).  My only problem
>is my credit card balance (too many electric train purchases this
>month).
>
>I relate to those of you in scientific and research backgrounds.. having
>worked at the CDC (compiling AIDS statistics), the Federal Home Loan
>Bank (compiling failing S&L statistics), Nielsen Media Research (the TV
>ratings), and the University of Georgia...  One of my biometrics
>professors there, the late (and quite well esteemed) Jerry Clutter, used

 88
>ratings), and the University of Georgia...  One of my biometrics
>professors there, the late (and quite well esteemed) Jerry Clutter, used
>to ask me when he saw me carrying my stack of printouts.. "_GOOD_
>Numbers?"  a reference to the fact that I ran up a hell of a bill back
>on my thesis research..and the runs were often flawed from one thing or
>another.  I'd be willing to see rerun this routine to see if it
>matches... but I've long lost the data ...  I did nonlinear volume
>equations for Slash Pine...  We ended up trashing these for the linear
>as we figured most self respecting foresters didn't have an exponent
>function on their calculators...  But I really don't think for the
>precision required that it would have made a difference...  I could say
>the same thing about the TV ratings... (but I'd better not...its a
>multibillion dollar business you know..) as folks just need "A" number
>to base their AD buying on.  I know all of you need GOOD numbers... I
>kinda wish that this company had an official spokesperson talking to all
>of you.. as they have on other Internet lists.
>
>My point is this... disregard the silly stats that folks are throwing
>around.. look hard at your apps.  If you, as a technology manager make

 93
>My point is this... disregard the silly stats that folks are throwing
>around.. look hard at your apps.  If you, as a technology manager make
>the arbitrary decision to pull all of your PCs out of production based
>on uncertainty over this, think of the impact on your business.  If you
>are a bonefide scientific user (as many of you are) get on the list for
>a replacement.
>
>Otherwise, we'll all see what comes out of the antidote path.. yes,
>you've heard me say that software emulation is too slow (i.e. the
>windows environment on the apple)... but given the optimization, and the
>limited nature of the flaw, it may nor be all that bad.  And there just
>might be some bargain basement deals coming out of all this..who knows?
>
>Sorry for the long-winded response... but I think we all need to put
>this in perspective.  I too would like to hear from SI concerning all
>this.  IT may take them awhile to fully assess the situation.  But if
>you ever looked at all of the bugs on the alert list .. or in the usage
>notes, it may take awhile for them to sort out the Pentium effects ;-)
>One of the more interesting things I've learned, is that memory chips

 99
>notes, it may take awhile for them to sort out the Pentium effects ;-)
>One of the more interesting things I've learned, is that memory chips
>are more likely to produce an error (parity problems).  Does that mean
>we should reduce our memory to a bare minimum to reduce the risk of  a
>possible error?  Just like memory, you  buy the Pentium for performance,
>and for a lot of applications it still makes a lot of sense.
>
>Another perspective on the flaw...
>
>Intel-Insider,
>Tom Skinner
>
>
>(as those of at UGA often said.. it must have been designed by a Georgia
>Tech engineer...)


--
Brent A. Blumenstein                   | voice:   206 667 4623

100
--
Brent A. Blumenstein                   | voice:   206 667 4623
Fred Hutchinson Cancer Research Center | fax:     206 667 4408
1124 Columbia St. MP-557               | e-mail:  brentb@orca.fhcrc.org
Seattle, WA 98117















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 52 of 78 100%      

Date: Thu, 15 Dec 1994 15:51:08 GMT
From: C Dhanwada <dhanwada@IASTATE.EDU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Is there an FAQ?

Hi SASers,

Is there an FAQ to this group? If so, please point me to its
location. Thanks!

Happy holidays!
-CD.







? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 53 of 78  76%      

Date: Thu, 15 Dec 1994 15:54:54 GMT
From: C Dhanwada <dhanwada@IASTATE.EDU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Question on SAS graphics printing

The following code generated a graph:

proc capability data=mysas.rcp1_9 graphics;
   var UGBT;
   title1 'Upper guide bearing temperature';
   spec LSL=140 USL=160;
   HISTOGRAM /NORMAL
   ;
run;

I am running SAS on DECstation 5000 (Ultrix platform). What is the
easiest way to

a) print the generated graph on our laserjet printer, or
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100

a) print the generated graph on our laserjet printer, or
b) saving it to a postscript file?

The menu File--Print... asks for a device, but does not recognise "lpr".
Thanks for your help.

-CD.












DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 54 of 78  35%      

Date: Thu, 15 Dec 1994 09:22:50 PST
From: Thomas M Skinner <Thomas_M_Skinner@CCM.FM.INTEL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re[2]: The Great Pentium Fire Drill

                                                Folsom, California
                                                December 15, 1994
                                                Fog, clearing 40's
Dear SAS-Lers,

Kevin F. Spratt writes:


>It seems that the issue of the bug has become overshadowed by
>how the bug is being exploited by various groups.  I tire of
>this debate and hope that others will soon follow.

>Regarding this article, the problem I am having is why this company
>felt the need to write it?  Given its tone, it might not be too
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 66
>Regarding this article, the problem I am having is why this company
>felt the need to write it?  Given its tone, it might not be too
>far fetched to hypothesize some vested interest in Intel.

>From Toms comments above, it seems good to know that those who agree
>with you have integrity and those that don't, don't.


Kevin, et al,

DQ is a market research firm that specializes in the computer industry.

I felt a need to post it as others felt a need to post our competitors official
statements (some might call it propaganda.)  DQ should be considered unbiased 
in
this as they receive their revenues independent of industry product
merchandising.  I suggest a trip to your local library to find out more about
them.


 98
them.

My only affiliation with DQ was several years ago when working in the 
Statistics
and Data Collection Research Department of Nielsen Media Research, when we
provided statistical sampling support to them (Both are companies of the D&B
corporation).

I too tire of the this, and I plan to take a sabbatical from it all for the 
next
few weeks.  My only condition is that others abandon this seemingly crusade
against Intel and stick to the facts as published by independent and reputable
sources. To date, I have published the official statements from intel at the
request of others, along with what little other factual data I could gathered
from sources such as Mathworks WWW (Dr. Nicely's post) and others.

The integrity issue you can judge for yourself, but keep in mind that IBM has a
vested interest in not seeing the Pentium succeed in the marketplace.


100
vested interest in not seeing the Pentium succeed in the marketplace.

Tom Skinner

















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 55 of 78  24%      

Date: Thu, 15 Dec 1994 09:17:05 PST
From: Thomas M Skinner <Thomas_M_Skinner@CCM.FM.INTEL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re[2]: The Great Pentium Fire Drill

Text item:

                                                Folsom, California
                                                December 15, 1994
                                                Fog, clearing 40's
Dear SAS-Lers,

Kevin F. Spratt writes:


>It seems that the issue of the bug has become overshadowed by
>how the bug is being exploited by various groups.  I tire of
>this debate and hope that others will soon follow.

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 45
>this debate and hope that others will soon follow.

>Regarding this article, the problem I am having is why this company
>felt the need to write it?  Given its tone, it might not be too
>far fetched to hypothesize some vested interest in Intel.

>From Toms comments above, it seems good to know that those who agree
>with you have integrity and those that don't, don't.


Kevin, et al,

DQ is a market research firm that specializes in the computer industry.

I felt a need to post it as others felt a need to post our competitors official
statements (some might call it propaganda.)  DQ should be considered unbiased 
in
this as they receive their revenues independent of industry product
merchandising.  I suggest a trip to your local library to find out more about

 67
this as they receive their revenues independent of industry product
merchandising.  I suggest a trip to your local library to find out more about
them.

My only affiliation with DQ was several years ago when working in the 
Statistics
and Data Collection Research Department of Nielsen Media Research, when we
provided statistical sampling support to them (Both are companies of the D&B
corporation).

I too tire of the this, and I plan to take a sabbatical from it all for the 
next
few weeks.  My only condition is that others abandon this seemingly crusade
against Intel and stick to the facts as published by independent and reputable
sources. To date, I have published the official statements from intel at the
request of others, along with what little other factual data I could gathered
from sources such as Mathworks WWW (Dr. Nicely's post) and others.

The integrity issue you can judge for yourself, but keep in mind that IBM has a

 88

The integrity issue you can judge for yourself, but keep in mind that IBM has a
vested interest in not seeing the Pentium succeed in the marketplace.

Tom Skinner


Text item: External Message Header

The following mail header is for administrative use
and may be ignored unless there are problems.

***IF THERE ARE PROBLEMS SAVE THESE HEADERS***.

Subject: Re: The Great Pentium Fire Drill
From: <CMDRABTS%UIAMVS@UICVM.UIC.EDU>
To: Thomas M Skinner <Thomas_M_Skinner@CCM.FM.INTEL.COM>
Reply-To: Kevin F. Spratt <Kevin-Spratt@UIOWA.EDU>
Date:    Thu, 15 Dec 94 09:35 CST

100
Reply-To: Kevin F. Spratt <Kevin-Spratt@UIOWA.EDU>
Date:    Thu, 15 Dec 94 09:35 CST
Received: from UIAMVS.BITNET (NJE origin CMDRABTS@UIAMVS) by UICVM.CC.UIC.EDU
 (LMail V1.2a/1.8a) with BSMTP id 0241; Thu, 15 Dec 1994 09:36:15 -0600
Received: from UICVM.CC.UIC.EDU by UICVM.UIC.EDU (IBM VM SMTP V2R2)
   with BSMTP id 1294; Thu, 15 Dec 94 09:36:15 CST
Message-Id: <9412151536.AA24087@hermes.intel.com>
Received: from UICVM-FDDI.CC.UIC.EDU by hermes.intel.com (5.65/10.0i); Thu, 15 
D
Received: from hermes.intel.com by relay.hf.intel.com with smtp
        (Smail3.1.28.1 #2) id m0rIIG3-000qDNC; Thu, 15 Dec 94 07:38 PST









DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 56 of 78 100%      

Date: Thu, 15 Dec 1994 09:50:27 -0800
From: Kenneth Chow <kenchow@LELAND.STANFORD.EDU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: proc build

hi, does anyone know what it means when you
got an error message 'Generic critical error'
while running 'proc build'? I am running
v607 on Sun. I also tried to use catalog=work.XXX
and I still got the same error message.

Any suggestions what/where to check? please
forward responses to this email. I appreciate
any help. Thanks

Ken



? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 57 of 78  21%      

Date: Thu, 15 Dec 1994 10:09:11 PST
From: Thomas M Skinner <Thomas_M_Skinner@CCM.FM.INTEL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Twas the Night before Star Trek...

OK folks,

I am going on vacation... happy holidays all..

Now for my traditional Night Before Christmas post..

This year for you trek fans...(No I didn't write this..it comes from an
independent and unbiased source.i.e.its making the rounds.)

Happy Hollidays all!

Skinner


? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 40


'Twas the night before Christmas, when all through the ship
Not a circuit was buzzing, not one microchip;
The phasers were hung in the armory securely,
In hopes that no alien would get up quite that early.

The crewmen were nestled all snug in their bunks
(Except for the few who were partying drunks);
And Picard in his nightshirt, and Bev in her lace,
Had just settled down for a late face to face...

When out in the hall there arose such a racket,
That we leapt from our beds, pulling on pant and jacket.
Away to the lifts we all shot like a gun,
Leapt into the cars and yelled loudly "Deck One!"

The red-alert lights, which flashed through the din,
Gave a luster of Hades to objects within.

 60
The red-alert lights, which flashed through the din,
Gave a luster of Hades to objects within.
When, what on the viewscreen, our eyes should behold,
But a weird kind of sleigh, and some guy who looked old.

But the glint in his eyes was so strange and askew,
That we knew in a moment it had to be Q.
His sleigh grew much larger as closer he came.
Then he zapped on the bridge and addressed us by name:

"It's Riker, It's Data, It's Worf and Jean-Luc!
It's Geordi, And Wesley, the genetic boy fluke!
To the top of the bridge, to the top of the hall!
Now float away! Float away! Float away all!"

As leaves in the autumn are whisked off the street,
So the floor of the bridge came away from our feet,
And up to the ceiling, our bodies they flew,
As the captain called out, "What the Hell's this, Q?!"

 79
And up to the ceiling, our bodies they flew,
As the captain called out, "What the Hell's this, Q?!"

The prankster just laughed and expanded his grin,
And, snapping his fingers, he vanished again.
As we took in our plight, and were looking around,
The spell was removed, and we crashed to the ground.

Then Q, dressed in fur from his head to his toe,
Appeared once again, to continue the show.
"That's enough!" cried the captain, "You'll stop this at once!"
And said Riker to Worf, "take aim at this dunce!"

"I'm deeply offended, Jean-Luc," replied Q,
"I just wanted to celebrate Christmas with you."
As we scoffed at his words, he produced a large sack.
He dumped out the contents and took a step back.

"I've brought gifts," he said, "just to show I'm sincere.

 98

"I've brought gifts," he said, "just to show I'm sincere.
There's something delightful for everyone here."
He sat on the floor, and dug into his pile,
And handed out gifts with his most charming smile:

"For Counsellor Troi, there's no need to explain.
Here's Tylenol-Beta for all of your pain.
For Worf I've some mints, as his breath's not too great,
And for Geordi LaForge, an inflatable date."

"For Wesley, some hormones, and Clearasil-plus;
For Data, a joke book, For Riker a truss.
For Beverly Crusher, there's sleek lingerie,
And for Jean-Luc, the thrill of seeing her that way."

And he sprang to his feet with a grin on his face.
And, clapping his hands, disappeared into space.
But we heard him exclaim as he dwindled from sight,

100
And, clapping his hands, disappeared into space.
But we heard him exclaim as he dwindled from sight,
"Merry Christmas to all, and to all a good flight!"

















[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 58 of 78 100%      

Date: Thu, 15 Dec 1994 13:31:43 +0000
From: Tom Minor <tminor@ATTMAIL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: sas under win32s...which version?

Ted:

I am sorry that I do not have an answer to your question.  I do have another
question to ask that indirectly relates to win32s.

My question:  Will SAS 6.10 for windows run in os/2 version 3 aka WARP???
              (Has anyone run SAS in the above manner????)

TIA for answers/comments to this question.


Regards,

Tom Minor
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 59 of 78  37%      

Date: Thu, 15 Dec 1994 13:31:00 EST
From: "Steven M. Kemp (Univ. of N. Carolina Davie Hall CB#3270 Chapel Hill,
     NC 27599)" <USTEVE@UNCMVS.OIT.UNC.EDU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: The Great Pentium Fire Drill

Dear Tom and SAS-L folk:

I have commented not at all on the Pentium bug, mostly because it's
way over my head.  However DataQuest's posting re-raises an issue
that has been lurking out there in previous e-mails.  I want to
put the issue out front and see if some of you gurus can speak to it
more authoritatively than I.

DataQuest says:

> Much
> engineering design work involves iterative calculations that
> work toward a solution. In these cases, the likelihood of the
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 70
> engineering design work involves iterative calculations that
> work toward a solution. In these cases, the likelihood of the
> bug occurring is increased, but its effect is totally negated by
> the subsequent iterative calculation.  If the flaw were to
> somehow cause a nonconvergence, the process would be started
> over with a new set of initial conditions, and the error would
> be eliminated.

This claim would seem to be true only where the algorithm is
guaranteed to converge to a global optimum if it converges at all.
Many neural networks and other non-linear optimization systems
readily fall into local optima when conditions are bad.  For some,
there is no way to determine if the optimum reached by the
convergence of the iteration is global or just local.

Consider the following worst case scenario.  One of the dozens
of recently popular non-linear optimization algorithms that has
major troubles with local optima is being used to solve a problem.
The algorithm is happily converging toward the GLOBAL optimum.

100
major troubles with local optima is being used to solve a problem.
The algorithm is happily converging toward the GLOBAL optimum.
Suddenly, it encounters the Pentium bug and the point on the
respnse surface, which has been gently gliding downslope to
the bottom of the deepest valley, teleports over the nearest
hill and, without giving notice to the user, slides down into
the adjacent very shallow valley, converging to a very bad
local optimum.

Is there anything about the Pentium bug that makes the above
scenario impossible?  Unlikely?  Given the growing popularity
of non-linear optimization techniques, even in commercial
products, isn't this a risk?

Awaiting expertise,

steve Kemp



[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 60 of 78  73%      

Date: Thu, 15 Dec 1994 13:49:59 CST
From: HILL@CMSUVMB.CMSU.EDU
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: Of Anecdotes, Antidotes, and Antipodean Consumers

On Thu, 15 Dec 1994 15:02:04 GMT  said:
>very comfortable flying that type of aircraft in future flights because I
>assume that
>there will be increased intensity in checking for the flaw that caused that
>aircraft to fail.  Something similar applies here.  Those of us criticising
>Intel
>are not necessarily rejecting Intel.  I suspect the P6 (or whatever it is
>called) will
>have a lower chance of having floating point problems as a result of this
>incident.
My advice,
1. if you have the chip, call the 800 number and work with Intel not SAS-l
2. if you don't have a machine with the chip, but thought of buying one ...
   wait, give Intel a chance to correct the problem on the machines already
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward
*

 

100
2. if you don't have a machine with the chip, but thought of buying one ...
   wait, give Intel a chance to correct the problem on the machines already
   purchased and wait your turn.
3. if you don't have the chip, don't plan to have the chip but still feel
   like flaming to a group, please start your group, call it scrooge,
   call it intel-pissed-off, I don't care but I would like to see atleast
   50% of the sas-l discussion related to sas. The chip doesn't effect me
   or my vm/cms applications. Think of those paying for email that are
   paying to see your flames.











DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 61 of 78 100%      

Date: Fri, 16 Dec 1994 06:22:00 AES
From: "Mason, Phil" <PMason@VCRPMRKT.TELECOM.COM.AU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: SASTrap: INCLUDE macro statement

%INCLUDE is NOT a macro statement.

So if you code:

     %if %bquote(_xyz_)= %then %include 'xyz.sas';

the semicolon terminates the %THEN statement, but the %INCLUDE statement is
generated as regular SAS code WITHOUT a semicolon. So you should code two
semi-colons - one for the %include and one for the %if/then.





? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 62 of 78  82%      

Date: Thu, 15 Dec 1994 19:55:49 GMT
From: ranan samanya <rsamanya@EDUSERV.RUG.AC.BE>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: SAS for OS/2 (long!) was (Re: Hotest OS/2 apps?)

@ Fri, 9 Dec 1994 23:02:39 -0500 John Michael Martz was heard grumbling:

> Sorry, but I don't know what a phenoplot is.  Can SYSTAT do

Phenoplot is a plot of data in real time axis.

> multidimensional scaling?  Structural modeling?  I thought not.

MDS, yes, together with factor and cluster analysis. However, I don't use
SYSTAT's multivariate capability, I use CANOCO. But what is structural
modelling?

</> the Indonesian Cita Ceria, under OS/2 <\>

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
</> the Indonesian Cita Ceria, under OS/2 <\>

ranan samanya

ranan.samanya@rug.ac.be
FIDONet 2:292/500.36














DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 63 of 78  11%      

Date: Thu, 15 Dec 1994 16:28:00 EST
From: Sally Muller <UNCSM1@UNCMVS.OIT.UNC.EDU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: SAS Institute's take on Pentium

----------------------------------------------------------------------
SUMMARY:  SAS Institutes posting on Pentium on TSNEWS-L
E-ADDR:   sally_muller@unc.edu
NAME:     Sally Muller
PH/ADDR:  919-962-5278  OIT CB#3460, UNC, Chapel Hill NC 27599
----------------------------------------------------------------------
Hey SAS-Lers!
I've been trying to keep up with Thomas Skinner's posting on
Pentium and just saw Steve Kemp posted something also.  Well this
was posted yesterday on SAS's TSNEWS-L and Eddie Routen sent it
to me to share with SAS-L.  I think it addresses many/most of
our concerns.  Will be interested to hear what you think!

Have a wonderful holiday!
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 21

Have a wonderful holiday!


----------------------------------------------------------------------
Intel Corporation has acknowledged a flaw in the floating point
unit of their Pentium chip. Certain rare combinations of numbers
in a floating point division (FDIV) will lead to a loss of
precision in the result.

To verify whether your machine has a flawed Pentium chip, run the
following SAS program and check the SAS Log for the results of
the PUT statement:

    Data;
      x = 4195835;
      y = 3145727;
      z = x - (x/y) * y;
      if abs(z)>x*1e-14 then put 'error: ' _all_;

 32
      z = x - (x/y) * y;
      if abs(z)>x*1e-14 then put 'error: ' _all_;
                        else put 'ok';
    run;

The Pentium, which uses the IEEE 754 standard for floating point
numbers, represents double-precision floating point numbers (the
numbers used in the SAS DATA step and for non-integer
computations in most SAS procedures) to a precision of about 15
decimal digits. The loss of precision due to the FDIV bug varies,
but in the worst known cases the results are accurate to about 4
significant decimal digits. For example, 4195835/3145727 yields
1.333739... on a flawed Pentium, whereas the correct result is
1.333820... . The error can occur in any digit after the 4th, and
seems to occur with equal frequency in the 6th and later digits,
with errors in the 5th digit occurring half as often as in other
digits.  It is important to assess the precision in terms of
significant digits, not in terms of decimal places, since the
errors are relative in magnitude.

 42
significant digits, not in terms of decimal places, since the
errors are relative in magnitude.

The FDIV bug occurs for about one in nine billion divisions with
randomly selected numbers according to Intel. This assessment has
been confirmed to within an order of magnitude by several people
who are not associated with Intel. However, the values for which
the bug occurs are not randomly or uniformly distributed.
According to Tim Coe, 90% of the problem divisors fall within one
of the following ranges multiplied by any integral power of two:

     3.0 > divisor >=  3.0 - 36*(2**-22)
     9.0 > divisor >=  9.0 - 36*(2**-20)
    15.0 > divisor >= 15.0 - 36*(2**-20)
    21.0 > divisor >= 21.0 - 36*(2**-19)
    27.0 > divisor >= 27.0 - 36*(2**-19)

The FDIV bug is believed not to occur for integer divisors less
than 4000. However, the bug does happen with values that are just

 53
The FDIV bug is believed not to occur for integer divisors less
than 4000. However, the bug does happen with values that are just
slightly less than an integer. An example from Vaughan R. Pratt
shows that 4.999999/14.999999 yields 0.333329... on a flawed
Pentium and 0.33333329... otherwise. Such values that are
slightly less than an integer, which Pratt calls "bruised
integers," can arise in floating point computations involving
multiplication and division of integers and are a serious concern
in situations where a large amount (such as 1E-8 or more) of
bruising can occur.  However, the SAS DATA step and most
procedures use double-precision arithmetic, so the amount of
bruising that occurs in typical calculations will rarely be more
than 1E-12.  According to Pratt's table, if the amount of
bruising is less than 1E-12, the result is accurate to at least
10 significant digits.  If you have a DATA step division
involving a value that you know should be a small integer in
exact arithmetic but that may have been bruised, you can use the
ROUND function to make the value an exact integer.


 63
ROUND function to make the value an exact integer.

The risk to which SAS users are exposed due to the FDIV bug
varies with the application. The greatest concern would attach to
applications in which a high degree of precision is required in
the results, such as some financial computations. The number of
floating point divisions obviously should be considered,
especially those in which the divisor is slightly less than an
integer. Another concern would be whether numeric errors can be
magnified during the computation.

Many statistical applications involve only divisions by small
integers, such as computing means and standard deviations of a
sample of less than 4000 observations; in such cases there
obviously is no risk. Many statistical computations involve few
divisions. For example, computing the coefficients in a multiple
regression on k predictors with PROC REG requires only k+1
divisions, although additional divisions are required for t
statistics and p values. On the other hand, PROC ORTHOREG does 6k

 73
divisions, although additional divisions are required for t
statistics and p values. On the other hand, PROC ORTHOREG does 6k
divisions for every observation. Hence, the chance of
encountering the FDIV bug is much greater with ORTHOREG than with
REG.

Numerical computations are described as "ill-conditioned" if a
small numerical error can be magnified during the computation. An
example is a multiple regression with highly correlated
predictors. If the FDIV bug is encountered in PROC REG with
uncorrelated predictors, the results are still likely to be
accurate to at least three significant digits. If the predictors
are highly correlated, it is possible that the error could be
magnified to the point that some results have no accurate digits.
In either case, however, the error introduced by the FDIV bug is
likely to be smaller than the statistical uncertainty.
Computations involving discontinuous functions, such as subset
regression or cluster analysis, are also ill-conditioned, since a
small change in the input can produce a large change in the

 84
regression or cluster analysis, are also ill-conditioned, since a
small change in the input can produce a large change in the
output. However, an error introduced by the FDIV bug is again
likely to be smaller than the statistical uncertainty.

Computationally intensive procedures such as CALIS or MIXED are
more likely than most procedures to encounter the FDIV bug simply
because they require more floating point computation than most
procedures.  Most of these computationally intensive procedures
do some form of nonlinear optimization. An FDIV error that occurs
during a nonlinear optimization is likely to be corrected at a
later stage of the computation. Hence these procedures are
probably at little more risk of producing incorrect final results
than are noniterative procedures such as REG.

RANUNI should not be affected by the FDIV bug since it has only
one floating point division, and the divisor, 2**31-1, is not
considered at risk. Neither should RANEXP, RANNOR, RANTBL, or
RANTRI be affected.  However, RANBIN, RANCAU, and RANGAM do

 94
considered at risk. Neither should RANEXP, RANNOR, RANTBL, or
RANTRI be affected.  However, RANBIN, RANCAU, and RANGAM do
contain divisions that could conceivably be affected.

To obtain a crude assessment of the risk of an FDIV error of
practical significance in statistical computations, we have rerun
large parts of of the test libraries for the SAS/ETS, SAS/IML,
SAS/OR, and SAS/STAT products on both Pentium and 486 machines.
We failed to find any discrepancy greater than what would
normally be expected due to numerical error. A few
inconsequential differences could be attributed to the Pentium's
greater accuracy in some transcendental functions.

Version 6.10 of the SAS System for the PC was built with a
compiler designed to take full advantage of improvements in the
486 and Pentium processors.  Examples of these optimizations
include instruction scheduling (re-arranging instructions to
allow for more concurrent execution) and instruction pairing
(selective use of instructions that have improved performance on

100
allow for more concurrent execution) and instruction pairing
(selective use of instructions that have improved performance on
this class of processors).  These optimizations have no effect on
the likelihood of SAS users encountering the FDIV bug in the
Pentium processor.

SAS Institute is vitally interested in the integrity of the
results produced by its products.  We would recommend that users
who receive error results from the program listed above contact
Intel's Customer Service at 800/628-8686 for information on
obtaining a corrected Pentium chip.









[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 64 of 78  73%      

Date: Thu, 15 Dec 1994 01:11:40 GMT
From: Ewan Grantham <grantham@MR.NET>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Help with ORDER BY/DISTINCT bug/info?

Currently working for an organization that has several tools for
accessing their DB2 database. When I execute a query to determine
where people practice and their specialties using MS Access, Andyne
GQL, and QMF, I get 151,084 rows returned. When the same SQL is
executed pass-through in SAS I get 149,588 rows.

Asking our local in-house folks, they thought it might be related
to a known (to them) bug with Order By (my SQL does a Distinct which
I gather does an Order By in the background) in certain queries.

Is this a known bug in MVS SAS? What conditions can precipitate it?
Is there anywhere on the Net or CompuServe to get info. directly from
SAS? If not, where else could I find out about known bugs, and known
patches?
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
SAS? If not, where else could I find out about known bugs, and known
patches?

Thanks again from a very confused data analyst,
Ewan Grantham

grantham@MR.NET
Ewan Grantham & Associates
"Innovation in Information"











DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 65 of 78  48%      

Date: Thu, 15 Dec 1994 17:01:49 EST
From: David Carroll <BDCARRD1%BUDGET.BITNET@uga.cc.uga.edu>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Stop Net Abuse - A Suggestion

Another list that I receive had some additional information
on trying to go after the chump who posted that chip liquid-
ation sale listing. Evidently netcom.com, his Internet Service
Provider, also had been the source of that previous "Green
Card" post (strange that both of these came from lawyers
behaving unethically?) At any rate netcom.com basically washed
their hands and said they couldn't police their users. Here is
the suggestion I posted to that list about what we, as proper
users of the net, might consider doing.
-------------------------------------------------------------
A recent postto PUBLIB-NET asked how lists can stop this abuse
if Internet Service Providers (ISPs) won't (can't?) police their
users. I have a suggestion. I will speak about capabilities
of Eric Thomas's listserv (but these might apply or might
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 92
users. I have a suggestion. I will speak about capabilities
of Eric Thomas's listserv (but these might apply or might
be added to other list software.) It is possible to set up
a list so that only private posting is allowed.
That means that if you are not a member of the list, then you
cannot post to it. It is also possible to set up the list
such that if you send a subscribe command, you do not get added
automatically by the listserv but rather your request is passed
on to a moderator and you are notified of this. With such a set-up
it would be very easy to give netcom.com and other rogue ISPs
a great incentive to clean up their acts. We could simply make
our lists private and when the moderators get a subscription
request from one of the offending ISPs, they send the requester
a polite notification that no one from his ISP is allowed to join
that list or many others. We could also suggest that they change
to a reputable ISP and then they'll be welcome. How long do you
think it would take netcom.com and their ilk to shape up or go
out of business once it becomes known that they can only provide
limited and unwelcome access?

100
out of business once it becomes known that they can only provide
limited and unwelcome access?
    Dave Carroll, NYS Div. of the Budget
    bdcarrd1@budget.bitnet     (or if path problems ...
    bdcarrd1%budget@cunyvm.cuny.edu















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 66 of 78 100%      

Date: Thu, 15 Dec 1994 16:44:09 CST
From: Louis Fox <louis@CIMARRON.WUSTL.EDU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: MIXREG

>
> I am trying to get information on a software package known as MIXREG,
> which does random effects regression (D. Hedecker).  Any information
> about how to obtain the software or reach D. Hedecker would be appreciated.
>

MIXREG is by no means easy to use.  You will probably be happier with PROC 
MIXED
available in SAS (see tech report P-229).  Be aware though, that PROC MIXED is
a resource hog, particularly with large datasets.




? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 67 of 78 100%      

Date: Thu, 15 Dec 1994 15:15:15 PST
From: Melvin Klassen <KLASSEN%UVVM.BITNET@uga.cc.uga.edu>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Free! solution to the Intel Pentium "FDIV" problem

All those "buzzwords" caught your attention, eh?  :-)

There's one inescapable conclusion from all the preceding verbiage:

    No amount of messages posted to SAS-L or COMP.SOFT-SYS.SAS
    is going to "solve" the Pentium problem, nor convince Intel
    to go further than their "lifetime warranty" promise.

Can we please choose to restrict our postings to SAS-related topics?

P.S. The 'LSTOWN-L@SEARN' BITNET mailing-list is *the* place
     for discussion for what "list-owners" need to do to react to,
     and to prevent, "spamming" incidents.

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 68 of 78   6%      

Date: Thu, 15 Dec 1994 23:49:01 GMT
From: Andrew Beveridge <beveridg@CLOUD9.NET>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: The Great Pentium Fire Drill

Thomas M Skinner (Thomas_M_Skinner@CCM.FM.INTEL.COM) wrote:
: Text item: Text_1

: Folks,

: Thought I'd pass this DataQuest item on...  as opposed to IBM, these
: folks have a reputation based on objectivity and integrity to watch out
: for.  (DQ is a company of the Dun&Bradstreet corporation)

Since the DQ article does not have anything to do with statistical
computing, I thought SAS Users might be interested in this analysis by
STATA, which assumes the one in 9 billion error rate posted by INTEL.

What the rate actually is 1 in 100,000,000 or one in 900,000,000 or one
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 12

What the rate actually is 1 in 100,000,000 or one in 900,000,000 or one
in 9,000,000,000 is not yet clear.  I wish SAS would do its own analysis
of its own procedures.  But I realize that the Pentium is only one
platform for them.



Subject: FDIV bug and statistics

I received this from my boss, the head of development of Stata, a
statistical package for DOS/Windows/Mac/Unix.  I thought it might be of
some interest to you guys here.  I'm posting this through my student
account because we don't have USENET access at Stata.

For those that have Stata, we have modified Stata to become Pentium-aware
to get around the bug.  Current users of Stata can be affected by this
bug though until the new release.


 18
bug though until the new release.

For those that are not familiar with Stata:

-an observation in Stata using a spreadsheet analogy is a row of data.  I
don't know how many variables (columns) were used in the samples but I
would guess at least 25 in 100 observations.
-maximum-likelihood estimation estimates the parameters which maximizes the
probability of observing the data you already observed.
-certification scripts mentioned are used to bug-test Stata.
-what is a typical sample size?  I don't know.  I've spoken to many people
who are in the hundred(s) area to the hundred-thousand area.
-test machine is a DELL/60mhz which does have the bug.

Memo follows:
----------------------------------------------------------------------------

A bug has been found in the Pentium cpu that affects division.  The
bug is reported to affect 1 in 9 billion divides and in such cases

 24
A bug has been found in the Pentium cpu that affects division.  The
bug is reported to affect 1 in 9 billion divides and in such cases
to return a result that lacks precision.  This paper is a crude attempt
to judge the likely impact of the bug on users of statistical software.

The problem we statisticians have in accessing this problem is that
we -- even those of us who write statistical software -- have no
accurate idea of how many divisions we do.  I have obtained estimates
by modifying Stata's internal source code to count FDIV operations.
Using this modified Stata, I ran some lengthy computations we use
for certifying Stata.  The data I collected is


-----------------------------------------------------------------------------
Table 1.   Data collected from modified Stata

     (1)           (2)    (3)          (4)      (5)          (6)
                                    lines of    pages =     FDIV/
                  FDIV   errs        output    lines/55     page

 30
                                    lines of    pages =     FDIV/
                  FDIV   errs        output    lines/55     page
    -------------------------------------------------------------
    base       998,527      0       20,782       378        2,642
    ado      1,331,294      0       20,867       379        3,512
    ado3       332,665      0        6,992       127        2,619
    ado4       504,675      0        5,039        92        5,486
    matrix      15,195      0        4,639        84          181
    -------------------------------------------------------------
    TOTAL    3,182,356      0       58,319     1,060        3,002

    ado2    13,884,782      0        3,221        59      235,335
    -------------------------------------------------------------
    TOTAL   17,067,138      0       61,540     1,119       15,252


Column 1 reports our internal name for the test script run.
Column 2 reports the number of FDIV operations performed in running
         the test script.

 36
Column 2 reports the number of FDIV operations performed in running
         the test script.
Column 3 reports the number of FDIV operations that were affected by
         the Pentium's flaw.
Column 4 reports the number of lines of output generated by Stata in
         running the test script.
Column 5 is the same as Column 4, divided by 55 and rounded.  It is
         a measure of the number of pages that would be printed if
         the computer output were printed.
Column 6 is merely Column 1 divided by Column 5.
-----------------------------------------------------------------------------

Thus, in total, the tests I ran totaled 1,119 pages of output and performed
17,067,138 double-precision divides.  In all of this output, the FDIV bug did
not bite once.  Assuming the probability of an individual divide resulting in
error is p = 1/(9e+09), the probability of observing no errors is

        P(no errors) = (1-p)^17,067,138 = .998105


 42
        P(no errors) = (1-p)^17,067,138 = .998105

or the probability of observing 1 or more errors is .001895.
(For your information, a exact, one-sided, 97.5% confidence interval for p,
based on these results, is 0 to 2.16e-07.)

I am now going to leave firm ground and make more speculative calculations
on the likely impact of the Pentium bug on statistical-software users.

In my data, you will note that the number of FDIVs per page of output is
much higher for the test script named "ado2" than for any of the others.
Script ado2 tests some of Stata's maximum-likelihood features and focuses
on iterative techniques.  I discuss the likelihood of the error being
observed separately for iterative and noninterative procedures below.


Noniterative procedures
-----------------------


 48
-----------------------

Taking the scripts other than ado2, there are an average of 3,002 FDIV
operations per page of output.  The data sets on which these scripts were
run, however, are small -- they average about 100 observations.  Were the
data sets larger, I would expect more divides per page than the 3,002 reported.
How much more?  I speculate that the number of divides is linear in the
log of the number of observations.  If that were true, then the total
number of divisions per page of output would be

              D = [3,002/log(100)] * log(N)
                = 1501 * log(N)                   (using log base 10)

Using this result, I produce the following table:



Table 2.  Speculative calculation for probability P of 1 or more FDIV
          errors in noniterative procedures, assuming the number of

 54
Table 2.  Speculative calculation for probability P of 1 or more FDIV
          errors in noniterative procedures, assuming the number of
          divisons are linear in the log of N, data set size.

                          P fail in     # of pages,     # of pages,
        N         D      1,000 pages     P = .01          P = .5
   ---------------------------------------------------------------
       100      3,002     .000333         29,908         2,077,638
     1,000      4,503     .000500         20,143         1,385,499
    10,000      6,004     .000667         14,955         1,038,819
   100,000      7,505     .000834         12,055           831,300
   ---------------------------------------------------------------



N is the assumed data set size.  D is the number of divisions I impute
based on my formula.  Column 3 reports the probability of 1 or more
failures in 1,000 pages of output.  Column 4 reports the number of
pages of output corresponding to P=.01, and column 5 reports the

 60
failures in 1,000 pages of output.  Column 4 reports the number of
pages of output corresponding to P=.01, and column 5 reports the
number of pages of output corresponding to P=.5.

For instance, if you use data sets of roughly 1,000 observations, the
probability you will observe 1 or more FDIV errors in 1,000 pages of
Stata output is .0005.  Looked at differently, you would have to review
20,143 pages of computer output to have a probability of 0.01 of the
bug biting.  In 1,385,449 pages of output, the bug is as likely to
strike as not.

Users of statistical software should be able to place themselves somewhere
on this table.  I suggest you think about how many pages of output you
generate per week, multiply by 50, and use the table to obtain an annual
risk.

If you use a package other than Stata, however, make an adjustment to
the calculation.  Stata tends to compress its output vertically relative
to other packages.  However many pages you generate using SAS, SPSS, etc.,

 66
the calculation.  Stata tends to compress its output vertically relative
to other packages.  However many pages you generate using SAS, SPSS, etc.,
divide that by two.  (We treat vertical space as precious in an attempt
to make screens hold as much information as possible.)


Iterative procedures
--------------------

The script ado2 averaged 235,335 FDIV operations per page of output
generated.  The script runs on data sets averaging 200 observations.
To generalize these results, I would expect the number of FDIV operations
to increase almost linearly with observations, and will use the
approximation

        D  =  (235,335/200) * N  =  1176.675 * N

for the total number of divisions.  I produce the table:


 72
for the total number of divisions.  I produce the table:

Table 3.  Speculative calculation for probability P of 1 or more FDIV
          errors for iterative procedures, assuming divisons are linear
          in N, data set size.

                          P fail in     # of pages,     # of pages,
        N         D      1,000 pages     P = .01          P = .5
   ---------------------------------------------------------------
       100     117,668      .01299          764           53,025
     1,000   1,176,675      .12256           77            5,301
    10,000  11,766,750      .72948            8              530
   100,000 117,667,500     1.00000           <1               53
   ---------------------------------------------------------------

As with Table 2, users of statistical software should be able to place
themselves somewhere on this table.  And, as before, if you use a package
other than Stata, divide your number of pages by two.


 78
other than Stata, divide your number of pages by two.


Table 3, however, reflects the probability of any error occuring.  In
the iterative techniques tested in script ado2, division errors that
occur during the maximization process will not affect the final result.
What is wrong in one iteration the next iteration will fix.  (The
path by which the result is obtained will change, but the result itself
will be correct if, from the last iteration to output, there are no
division errors.)

As a way of approximating this, I return to the results from the test
scripts.  I use the observed 3,002 divides per page as an estimate of
the number of divides per page of output generated from the onset of
the last iteration.  This time, however, I generalize the results by
assuming the number of divisions is linear in data set size:

           D  =  (3,002/100) * N  =  30.02 * N


 84
           D  =  (3,002/100) * N  =  30.02 * N


Table 4.  Speculative calculation for probability P of 1 or more FDIV
          errors in iterative procedures that affects results,
          assuming the number of divisons are linear in the log of N,
          data set size.

                          P fail in     # of pages,     # of pages,
        N         D      1,000 pages     P = .01          P = .5
   ---------------------------------------------------------------
       100      3,002     .000333         29,908         2,077,638
     1,000     30,020     .00333           3,014           207,826
    10,000    300,200     .032805            301            20,781
   100,000  3,002,000     .283629             30             2,078
   ---------------------------------------------------------------

This, I think, is a reasonable approximation to the affect of the FDIV
bug on the final results of iterative techniques.

 90
This, I think, is a reasonable approximation to the affect of the FDIV
bug on the final results of iterative techniques.


Summary
-------

Various claims have been made about the FDIV bug, varying from apocalyptic
to, by Intel, so benign as to strike a user only once every 27,000 years.
(A recent variation in this is that the mean time to the bug biting is
longer than the mean time to failure of the other components of the computer.)
Both are wrong.

Most users of noniterative statistical procedures are indeed unlikely to be
struck by the bug.  Intense users -- users producing say 500 pages per
week -- do have a chance of observing the bug in a year.

Users of iterative statistical procedures have more reason for concern
although, this is offset by the fact that even among intense users,

 96
Users of iterative statistical procedures have more reason for concern
although, this is offset by the fact that even among intense users,
few produce 500 pages per week of output.  If one performs maximum-likelihood
estimation routinely on data sets of 1,000 or more observations, you
are likely to observe the bug at least once over the course of a year.
Users of larger data sets will almost certainly encounter the bug and
more than once.  I chances that the bug will strike at a point where
it effects final results, however, is greatly diminished from this.  Still,
intense users of large data sets face a reasonable risk that it will
affect the final results.

How much will it effect results? I suspect the probability of meaningfully
affecting results given an error is small, but have no way of casting any
empirical light on that matter.

Finally, remember that I have taken as given that the probability of the FDIV
error is 1/(9e+09); I have no independent evidence to support it.  I have
merely taken this probability, along with empirical data on the number of
divisions statistical software users perform, and performed various

100
merely taken this probability, along with empirical data on the number of
divisions statistical software users perform, and performed various
manipulations.


-- Bill
wgould@stata.com
--
                        - Dr. Strangelove -
  There are only two kinds of guys in this world... those that would do
   Ginger and those that would do Mary Anne.  Well, I guess there are a
                 few sickos that would do Mrs. Howell.








DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 69 of 78  35%      

Date: Thu, 15 Dec 1994 23:53:54 GMT
From: Andrew Beveridge <beveridg@CLOUD9.NET>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: Re[2]: The Great Pentium Fire Drill

Thomas M Skinner (Thomas_M_Skinner@CCM.FM.INTEL.COM) wrote:
:                                                 Folsom, California
:                                                 December 15, 1994
:                                                 Fog, clearing 40's
: Dear SAS-Lers,

: Kevin F. Spratt writes:


: >It seems that the issue of the bug has become overshadowed by
: >how the bug is being exploited by various groups.  I tire of
: >this debate and hope that others will soon follow.

: >Regarding this article, the problem I am having is why this company
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 66

: >Regarding this article, the problem I am having is why this company
: >felt the need to write it?  Given its tone, it might not be too
: >far fetched to hypothesize some vested interest in Intel.

: >From Toms comments above, it seems good to know that those who agree
: >with you have integrity and those that don't, don't.


: Kevin, et al,

: DQ is a market research firm that specializes in the computer industry.

: I felt a need to post it as others felt a need to post our competitors
official
: statements (some might call it propaganda.)  DQ should be considered unbiased
in
: this as they receive their revenues independent of industry product
: merchandising.  I suggest a trip to your local library to find out more about

 98
: this as they receive their revenues independent of industry product
: merchandising.  I suggest a trip to your local library to find out more about
: them.

: My only affiliation with DQ was several years ago when working in the
Statistics
: and Data Collection Research Department of Nielsen Media Research, when we
: provided statistical sampling support to them (Both are companies of the D&B
: corporation).

I think that for statistics the three things we know are:  1) SAS will
not guarantee accuracy using the Pentium;  2)  SPSS's test bed fails when
run on Pentium;  3)  STATA has done an analysis that seems to indicate
that for heavy use of ML statistics, a user runs the risk of non-trivial
error from time to time.  This is based upon Intel's 9 billion before an
error analysis.  So there you are.

Andy Beveridge


100
Andy Beveridge

P.S. Stata post is follow-up to fire drill above.

















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 70 of 78 100%      

Date: Mon, 5 Dec 1994 16:03:17 -0500
From: Paul Wehr <wehrp@AA.WL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: What Platform am I on?

I have an application that needs to run (conditionally) on both MVS and UNIX,
and it needs to know what it is currently running on.  Is there a system macro
variable or somthing that will tell me?

tx

-paul
--

    "Megabytes, Gigabytes, Trilobytes?"            | Why would Parke-Davis
Paul Wehr:  Ann Arbor, MI                          | want me to say anything
NewtonMail:  wally@online.apple.com                | on their behalf?
Parke-Davis:  wehrp@aa.wl.com                      |

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 71 of 78  11%      

Date: Thu, 15 Dec 1994 21:54:00 EST
From: Sally Muller <UNCSM1@UNCMVS.OIT.UNC.EDU>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Pentium alert....correction to SAS Inst. take on Pentium!

----------------------------------------------------------------------
SUMMARY:  Correction to SAS Institutes posting on Pentium
E-ADDR:   sally_muller@unc.edu
NAME:     Sally Muller
PH/ADDR:  919-962-5278  OIT CB#3460, UNC, Chapel Hill NC 27599
----------------------------------------------------------------------
Well if Warren Sarle, one of SI's main statistical proc  developers,
goes to the trouble of e-mailing me and calling me regarding my
posting the INCORRECT memo on  SAS Institute's opinions re the
Pentium.....I know that there must have been a major flaw in
the original message I sent you.  To tell you the truth, I haven't
had a chance to compare the two memos 'cause Warren asked that
I post this ASAP.  Please disregard my first posting, though
and replace it with this one.  Thanks, and so sorry for confusion!
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 21
I post this ASAP.  Please disregard my first posting, though
and replace it with this one.  Thanks, and so sorry for confusion!

-------------- SAS Institute's Memo on Pentium -------------------------

Intel Corporation has acknowledged a flaw in the floating point
unit of their Pentium chip. Certain rare combinations of numbers
in a floating point division (FDIV) will lead to a loss of
precision in the result.

To verify that your machine has a flawed Pentium chip, run the
following SAS program and check the SAS Log for the results of
the PUT statement:

    Data;
      x = 4195835;
      y = 3145727;
      z = x - (x/y) * y;
      if abs(z)>x*1e-14 then put 'error: ' _all_;

 30
      z = x - (x/y) * y;
      if abs(z)>x*1e-14 then put 'error: ' _all_;
                        else put 'ok';
    run;

The Pentium, which uses the IEEE 754 standard for floating point
numbers, represents double-precision floating point numbers (the
numbers used in the SAS DATA step and for non-integer
computations in most SAS procedures) to a precision of about 15
decimal digits. The loss of precision due to the FDIV bug varies,
but in the worst known cases the results are accurate to about 4
significant decimal digits. For example, 4195835/3145727 yields
1.333739... on a flawed Pentium, whereas the correct result is
1.333820... . The error can occur in any digit after the 4th, and
seems to occur with equal frequency in the 6th and later digits,
with errors in the 5th digit occurring half as often as in other
digits.  It is important to assess the precision in terms of
significant digits, not in terms of decimal places, since the
errors are relative in magnitude. Either number in the division

 40
significant digits, not in terms of decimal places, since the
errors are relative in magnitude. Either number in the division
can be multiplied by a power of two without changing the relative
error.

The FDIV bug occurs for about one in nine billion divisions with
randomly selected numbers according to Intel. This assessment has
been confirmed to within an order of magnitude by several people
who are not associated with Intel. However, the values for which
the bug occurs are not randomly or uniformly distributed.
According to Tim Coe, 90% of the problem divisors fall within one
of the following ranges multiplied by any integral power of two:

     3.0 > divisor >=  3.0 - 36*(2**-22)
     9.0 > divisor >=  9.0 - 36*(2**-20)
    15.0 > divisor >= 15.0 - 36*(2**-20)
    21.0 > divisor >= 21.0 - 36*(2**-19)
    27.0 > divisor >= 27.0 - 36*(2**-19)


 50
    27.0 > divisor >= 27.0 - 36*(2**-19)

The FDIV bug is believed not to occur for integer divisors less
than 4000. However, the bug does happen with values that are just
slightly less than an integer. An example from Vaughan R. Pratt
shows that 4.999999/14.999999 yields 0.333329... on a flawed
Pentium and 0.33333329... otherwise. Such values that are
slightly less than an integer, which Pratt calls "bruised
integers," can arise in floating point computations involving
multiplication and division of integers and are a serious concern
in situations where a large amount (such as 1E-8 or more) of
bruising can occur.  However, the SAS DATA step and most
procedures use double-precision arithmetic, so the amount of
bruising that occurs in typical calculations will rarely be more
than 1E-12.  According to Pratt's table, if the amount of
bruising is less than 1E-12, the result is accurate to at least
10 significant digits.  If you have a DATA step division
involving a value that you know should be a small integer in
exact arithmetic but that may have been bruised, you can use the

 60
involving a value that you know should be a small integer in
exact arithmetic but that may have been bruised, you can use the
ROUND function to make the value an exact integer.

The risk to which SAS users are exposed due to the FDIV bug
varies with the application. The greatest concern would attach to
applications in which a high degree of precision is required in
the results, such as many financial computations. The number of
floating point divisions obviously should be considered,
especially those in which the divisor is slightly less than an
integer. Another concern would be whether numeric errors can be
magnified during the computation.

Many statistical applications involve only divisions by small
integers, such as computing means and standard deviations of a
sample of less than 4000 observations; in such cases there
obviously is no risk. Many statistical computations involve few
divisions. For example, computing the coefficients in a multiple
regression on n predictors with PROC REG requires only n+1

 70
divisions. For example, computing the coefficients in a multiple
regression on n predictors with PROC REG requires only n+1
divisions. As many as 60 additional divisions are required for
each t statistic and p value, but the worst possible errors in
probability computations are unlikely to show up in the customary
4 decimal places that SAS procedures print. On the other hand,
PROC ORTHOREG does 6n divisions for every observation. Hence, the
chance of encountering the FDIV bug is much greater with ORTHOREG
than with REG.

Numerical computations are described as "ill-conditioned" if a
small numerical error can be magnified during the computation. An
example is a multiple regression with highly correlated
predictors. If the FDIV bug is encountered in PROC REG with
uncorrelated predictors, the results are still likely to be
accurate to at least three significant digits.  If the predictors
are highly correlated, it is possible that the error could be
magnified to the point that some results have no accurate digits,
but the more likely result is that the problem will incorrectly

 80
magnified to the point that some results have no accurate digits,
but the more likely result is that the problem will incorrectly
be declared singular. In either case, however, the error
introduced by the FDIV bug is likely to be smaller than the
statistical uncertainty.  Computations involving discontinuous
functions, such as subset regression or cluster analysis, are
also ill-conditioned, since a small change in the input can
produce a large change in the output. However, an error
introduced by the FDIV bug is again likely to be smaller than the
statistical uncertainty.

Computationally intensive procedures such as CALIS or MIXED are
more likely than most procedures to encounter the FDIV bug simply
because they require more floating point computation than most
procedures.  Most of these computationally intensive procedures
do some form of nonlinear optimization. An FDIV error that occurs
during a nonlinear optimization is likely to be corrected at a
later stage of the computation. Hence these procedures are
probably at little more risk of producing incorrect final results

 90
later stage of the computation. Hence these procedures are
probably at little more risk of producing incorrect final results
than are noniterative procedures such as REG.

RANUNI should not be affected by the FDIV bug since it has only one
floating point division, and the divisor, 2**31-1, is not considered
at risk. Neither should RANEXP, RANNOR, RANTBL, or RANTRI be affected.
However, RANBIN, RANCAU, and RANGAM do contain divisions that could
conceivably be affected.

To obtain a crude assessment of the risk of an FDIV error of
practical significance in statistical computations, we have rerun
large parts of of the test libraries for the SAS/ETS, SAS/IML,
SAS/OR, and SAS/STAT products on both Pentium and 486 machines.
We failed to find any discrepancy greater than what would
normally be expected due to numerical error. A few
inconsequential differences could be attributed to the Pentium's
greater accuracy in some transcendental functions.


100
greater accuracy in some transcendental functions.

Version 6.10 of the SAS System for the PC was built with a
compiler designed to take full advantage of improvements in the
486 and Pentium processors.  Examples of these optimizations
include instruction scheduling (re-arranging instructions to
allow for more concurrent execution) and instruction pairing
(selective use of instructions that have improved performance on
this class of processors).  These optimizations have no effect on
the likelihood of SAS users encountering the FDIV bug in the
Pentium processor.

SAS Institute is vitally interested in the integrity of the
results produced by its products.  We recommend that if you have
a Pentium that exhibits the problem and you are concerned about
possible errors, please contact Intel's Customer Service at
800/628-8686 for information on obtaining a corrected Pentium
chip.


[Already at end of message]

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 72 of 78  95%      

Date: Fri, 16 Dec 1994 00:27:43 -0500
From: RWnewmedia@aol.com
To: wwwwwh@phantom.com
Subject: stuff

Hi Stephen,

Good seeing you today; configuring softwarte to modem and working fine.

Could you send me an invoice for the services on Openetwork letterhead?
e-mail rwnewmedia@aol.com
fax: 212/679-2867

How do I get onto pipeline.

Speak to you soon

Rob

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

  PINE 3.89   FOLDER INDEX                 Folder: INBOX  Message 72 of 78      

  D 58  Dec 15 Tom Minor           (1,360) Re: sas under win32s...which version?
  D 59  Dec 15 Steven M. Kemp (Un  (3,035) Re: The Great Pentium Fire Drill     
  D 60  Dec 15 HILL@CMSUVMB.CMSU.  (2,002) Re: Of Anecdotes, Antidotes, and Anti
  D 61  Dec 16 Mason, Phil         (1,185) SASTrap: INCLUDE macro statement     
  D 62  Dec 15 ranan samanya       (1,463) Re: SAS for OS/2 (long!) was (Re: Hot
  D 63  Dec 15 Sally Muller        (9,049) SAS Institute's take on Pentium      
  D 64  Dec 15 Ewan Grantham       (1,776) Help with ORDER BY/DISTINCT bug/info?
  D 65  Dec 15 David Carroll       (2,906) Stop Net Abuse - A Suggestion        
  D 66  Dec 15 Louis Fox           (1,231) MIXREG                               
  D 67  Dec 15 Melvin Klassen      (1,392) Free! solution to the Intel Pentium "
  D 68  Dec 15 Andrew Beveridge   (14,258) Re: The Great Pentium Fire Drill     
  D 69  Dec 15 Andrew Beveridge    (2,936) Re: Re[2]: The Great Pentium Fire Dri
  D 70  Dec  5 Paul Wehr           (1,368) What Platform am I on?               
  D 71  Dec 15 Sally Muller        (9,619) Pentium alert....correction to SAS In
+   72  Dec 16 RWnewmedia@aol.com    (689) stuff                                
  N 73  Dec 15 Jack Hamilton       (3,724) Re: Stop Net Abuse - A Suggestion    
  N 74  Dec  6 Paul Wehr           (2,721) Re: Wanted: Examples of SAS code for 
  N 75  Dec 16 Tom Robinson        (1,616) Re: Greetings O wise SAS ones!       
  N 76  Dec 16 RobinWay            (1,876) Re: PROC STEPWISE -- Output of predic

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V [ViewMsg]  N NextMsg   Spc NextPage    U Undelete    F Forward

73
NEW
+   72  Dec 16 RWnewmedia@aol.com    (689) stuff                                
  N 73  Dec 15 Jack Hamilton       (3,724) Re: Stop Net Abuse - A Suggestion    


72
   
  N 73  Dec 15 Jack Hamilton       (3,724) Re: Stop Net Abuse - A Suggestion    
+   72  Dec 16 RWnewmedia@aol.com    (689) stuff                                


  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 72 of 78  95%      

Date: Fri, 16 Dec 1994 00:27:43 -0500
From: RWnewmedia@aol.com
To: wwwwwh@phantom.com
Subject: stuff

Hi Stephen,

Good seeing you today; configuring softwarte to modem and working fine.

Could you send me an invoice for the services on Openetwork letterhead?
e-mail rwnewmedia@aol.com
fax: 212/679-2867

How do I get onto pipeline.

Speak to you soon

Rob

? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
Rob

speak to you soon

















  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 73 of 78  24%      

Date: Thu, 15 Dec 1994 22:03:22 CST
From: Jack Hamilton <hamiltja@HCCOMPARE.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: Stop Net Abuse - A Suggestion

David Carroll <BDCARRD1%BUDGET.BITNET@uga.cc.uga.edu> wrote:

>Another list that I receive had some additional information
>on trying to go after the chump who posted that chip liquid-
>ation sale listing. Evidently netcom.com, his Internet Service
>Provider, also had been the source of that previous "Green
>Card" post

That's not entirely correct.  C&S posted from a number of different sites.

>(strange that both of these came from lawyers
>behaving unethically?)

The chip poster said he was an actuary, not a lawyer.
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 74 of 78  39%      

Date: Tue, 6 Dec 1994 09:21:45 -0500
From: Paul Wehr <wehrp@AA.WL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: Wanted: Examples of SAS code for drug trials

In article <3959211405121994/A53444/MEDEC/118C2B953700*@mr.syntex.com>, Faith
Renee Sloan 415-855-5832 <Faith.Sloan@SYNTEX.COM> writes:
> mr self couldn't have said it better.  would i feel comfortable hiring mr.
shain
> as an independent contractor?  no, i wouldn't.  mr shain would do better at
> soliciting business in his current area of 'expertise' whatever that may be.
if
> mr. shain is an excellent SAS programmer and listener, then the
> industry-specifics is irrelevant.
>
> aahhhhhhhh....i feel better now. you won't hear from me on this issue again.
>
> Faith Renee Sloan
> Senior Project Analyst (Expert)
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

 75
> Faith Renee Sloan
> Senior Project Analyst (Expert)
> Syntex, affiliate of the Roche Group
> Mycophenolate Mofetil Transplant Program
> Palo Alto, CA 94303
> faith.sloan@syntex.com
> http://www.syntex.com/welcome.html
> ***Life is too SHORT--De-jobbing is IN!!***

On the other hand, imagine where pharmaceutical research would be
if the programmers were free to exchange code of any kind--macro
libraries, data views, even whole applications...  That Lab data
management application that you have been slaving away at over
the past three months is the same one that has already been done
in 12 other companies, and is currently being developed in another
five.  Kind of makes you wonder who is to gain with this concept
of "proprietary" code, except for the gainfully-employed legions of
SAS programmers, of course ;)


100
SAS programmers, of course ;)


P.S., I think Ian Whitlock has somehow let slip his "proprietary"
%age macro.  I hope he doesn't get fired :)

-paul

--

    "Megabytes, Gigabytes, Trilobytes?"            | Why would Parke-Davis
Paul Wehr:  Ann Arbor, MI                          | want me to say anything
NewtonMail:  wally@online.apple.com                | on their behalf?
Parke-Davis:  wehrp@aa.wl.com                      |






DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 75 of 78  95%      

Date: Fri, 16 Dec 1994 03:27:05 GMT
From: Tom Robinson <robinson@ATLANTIS.ACTRIX.GEN.NZ>
Reply to: tomr.bnz@mhsgate.nui-wgtn.gen.nz
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: Greetings O wise SAS ones!

In article <01HKN1EX2BK6008JM7@mr.lilly.com>,
CATLEY DENNIS B  <CATLEY_DENNIS_B@LILLY.COM> wrote:
>I just had a user present me with an SCL error that's a new one for me and
>would love to hear some SCL expertise spilled forth to explain it.
>
>the error is 'Out of file handles creating WORK'
>with a hopefully related 'Appendage auto-load failure' message

If you're running under Windoze I suggest increasing the number of
file handles in the config.sys
--
  8    Bare          What does the 95 in Windows 95 stand for?         vuU Uuv
o-+-o  Foot           The shipping date in hexadecimal - 2149              GCS
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
  8    Bare          What does the 95 in Windows 95 stand for?         vuU Uuv
o-+-o  Foot           The shipping date in hexadecimal - 2149              GCS
 < >   Guru    -d+(-) p(--) c++ !l u+ e* m+(---) s+/ n+ h@ f !g w+ t+ r+ y+(*)

















DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 76 of 78  79%      

Date: Fri, 16 Dec 1994 01:35:14 -0500
From: RobinWay <robinway@AOL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: PROC STEPWISE -- Output of predicted & residuals

In article <3cnuvi$ll7@tequesta.gate.net>, jjmacak3@gate.net writes:

<<I use both PROC GLM and PROC STEPWISE for
multiple regression analyses.  I know that PROC GLM offers
an option to print observed, predicted, residuals, and CLM95.
However, is there a way to use PROC STEWISE and output
the predicted and residual values to a dataset?  I use SAS 6.08
for Windows.>>

First, upgrade to version 6.10, and then switch to Proc Reg, and choose
the Adjrsq option, or the rsquare option, or the forward, backward,
stepwise, etc. options.  The selection you make determines how independent
variables are added to (removed from) the model.  Then Proc Reg permits
the Outest= option to  output parm estimates.
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
variables are added to (removed from) the model.  Then Proc Reg permits
the Outest= option to  output parm estimates.

On a more theoretical note, IMHO, stepwise regression (as it had been
drilled into me over and over again in school) is fine for doing
exploratory analysis, but modeling should be guided by theory first and by
diagnostic statistics last.  ;-)













DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 77 of 78  67%      

Date: Fri, 16 Dec 1994 01:40:07 -0500
From: RobinWay <robinway@AOL.COM>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Re: sas under win32s...which version?

In article:

<<One of my net administrators is running win32s v1.1.88 on his network.
The spec sheets for SAS v6.10 specifies that v6.10 supports win32s
v1.15.111.
Tech support in Cary further states than v1.15.111 is the *only* version
of
win32s supported.>>

In order to install sas version 6.10 for windows, SI includes some
supplementary files which must be installed first--these will install the
files necessary to convert your windows setup to Win32s v1.15.111.  So if
you want to bypass your net administrator (and suffer the potential
consequences), you may not need to wait for the entire net to
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
you want to bypass your net administrator (and suffer the potential
consequences), you may not need to wait for the entire net to
upgrade--just install the software locally.

Of course, there may be all sorts of network-specific details at your site
of which I am woefully unaware, but our Netware-based LAN doesn't seem to
mind (or even acknowledge) that I am running a "new" version of Windows.

Robin Way
Associate, Barakat & Chamberlin
robinway@aol.com









DEL
  PINE 3.89   MESSAGE TEXT            Folder: INBOX  Message 78 of 78  79%      

Date: Fri, 16 Dec 1994 09:43:50 +0000
From: HEDDERLE <duncan.hedderley@AFRC.AC.UK>
To: Multiple recipients of list SAS-L <SAS-L@uga.cc.uga.edu>
Subject: Segmentation Violation" on SAS6.07 under Ultrix

Hello,
I'm running SAS 6.07.01 under Ultrix on a DecStation 5000 - or at
least I'm trying to. I'm working on a program which doesn't involve
particularly large data sets (about 100 obs x 20 variables, or 2000
obs x 5 variables) or particularly fancy code (though there are a
lot of Proc Corrs and Proc Regs, and I'm reshaping the data sets
a lot), but when I try to run it it gives me a "Segmentation Violation
in Task OUTPUT" at the end of the log, and every time I try to
change windows they shut.
I haven't got a CLUE what a "Segmentation Violation" is, so I can't
even start working out what's wrong with my code (and I'm fairly
sure it's a code problem, not a hardware one - I've tried it on
two machines and they've both bombed). Please could someone
enlighten me?
? Help       M Main Menu  P PrevMsg     - PrevPage    D Delete      R Reply
O OTHER CMDS V ViewAttch  N NextMsg   Spc NextPage    U Undelete    F Forward

100
two machines and they've both bombed). Please could someone
enlighten me?
Many thnaks in advance

Duncan Hedderley

Institute of Food Research, Reading, UK













DEL

[Last message deleted]
Really quit pine? (y/n/^C) [y]:                                                 

Yes

[Closing "INBOX"...]
Expunge the 34 deleted messages from "INBOX"? (y/n) [y]:                        

Yes

[Closing "INBOX". Keeping 44 messages and deleting 34]




Pine finished


(10:02am)        [ Phantom Access Technologies, Inc. (TM) ]         (? for Menu)

[Main Menu]: o








     [ wwwwwh ] Leaving the MindVox Thoughtscape on [16-Dec-94] / [10:02am]


NO CARRIER
